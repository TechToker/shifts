{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292fe24e",
   "metadata": {},
   "source": [
    "## Предсказание траекторий автомобилей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da8b63d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.16\r\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42fc3843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.16\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())\n",
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3c86102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87261e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Video object>",
      "text/html": "<video src=\"motion-prediction-video.mp4\" controls  width=\"400\"  height=\"400\">\n      Your browser does not support the <code>video</code> element.\n    </video>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"motion-prediction-video.mp4\", width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38511b1",
   "metadata": {},
   "source": [
    "## Соревнование https://research.yandex.com/shifts/vehicle-motion-prediction\n",
    "\n",
    "Трек по предсказанию траекторий движения автомобилей. Соревнование в целом посвящено исследованию подходов к оценке неопределенности и устойчивости моделей к сдвигам во входных данных.\n",
    "\n",
    "![Ансамбль моделей](uncertainty.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb39ade",
   "metadata": {},
   "source": [
    "## Что представляют из себя данные\n",
    "\n",
    "Единицей данных в датасете является сцена. Сцена содержит в себе информацию о динамических объектах (автомобилях и пешеходах), векторную карту дорожного графа, состояния светофоров, теги для сцены и отдельных агентов.\n",
    "\n",
    "Данные в сцене разбиты на две зоны: прошлое и будущее. Для каждого автомобиля нам известны следующие параметры:\n",
    "- уникальный идентификатор\n",
    "- положение в глобальной системе координат\n",
    "- размеры\n",
    "- скорость\n",
    "- ускорение\n",
    "\n",
    "Аналогичные данные известны для самого беспилотника. Для пешехедов данные ограничиваются id, положением, размером и скоростью.\n",
    "\n",
    "Дорожный граф содержит в себе информацию о полосах, полигон дороги, полигоны пешеходных переходов.\n",
    "\n",
    "Ссылка на тест сет, с которым поработаем на семинаре: https://disk.yandex.ru/d/M_4ED0r19OnSrg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b70e9f5",
   "metadata": {},
   "source": [
    "## API для работы с датасетом"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6b7d3",
   "metadata": {},
   "source": [
    "Рекомендую установить в virtualenv, чтобы не ставить лишние пакеты в хостовую систему.\n",
    "```\n",
    "git clone git@github.com:yandex-research/shifts.git\n",
    "cd shifts/sdc\n",
    "pip install .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6908385e",
   "metadata": {},
   "source": [
    "## Посмотрим на данные\n",
    "\n",
    "Исходные сырые данные хранятся в формате protubuf (https://developers.google.com/protocol-buffers), он позволяет удобно хранить и рабоать со структурированными объектами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2243eca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/techtoker/tools/anaconda3/envs/yandex_sdc/lib/python3.8/site-packages/ysdc_dataset_api/utils/transform.py:90: NumbaPerformanceWarning: '@' is faster on contiguous arrays, called on (array(float32, 2d, A), array(float32, 2d, C))\n",
      "  res = transform @ ph\n",
      "/home/techtoker/tools/anaconda3/envs/yandex_sdc/lib/python3.8/site-packages/numba/core/typing/npydecl.py:913: NumbaPerformanceWarning: '@' is faster on contiguous arrays, called on (array(float32, 2d, A), array(float32, 2d, C))\n",
      "  warnings.warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "from ysdc_dataset_api.utils import read_scene_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b458d6be",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../datasets/canonical-eval-data/011/011000.pb'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m scene \u001B[38;5;241m=\u001B[39m \u001B[43mread_scene_from_file\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m../datasets/canonical-eval-data/011/011000.pb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/tools/anaconda3/envs/yandex_sdc/lib/python3.8/site-packages/ysdc_dataset_api/utils/reading.py:80\u001B[0m, in \u001B[0;36mread_scene_from_file\u001B[0;34m(filepath)\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread_scene_from_file\u001B[39m(filepath: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Scene:\n\u001B[1;32m     72\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Reads and deserializes one protobuf scene from the given file.\u001B[39;00m\n\u001B[1;32m     73\u001B[0m \n\u001B[1;32m     74\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;124;03m        Scene: protobuf message\u001B[39;00m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 80\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m     81\u001B[0m         scene_serialized \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m     82\u001B[0m     scene \u001B[38;5;241m=\u001B[39m Scene()\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../datasets/canonical-eval-data/011/011000.pb'"
     ]
    }
   ],
   "source": [
    "scene = read_scene_from_file('../datasets/canonical-eval-data/011/011000.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scene.path_graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c49ed6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scene' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mТип объекта: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(scene)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mПоля объекта: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m[field\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mfield\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mdir\u001B[39m(scene)\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mif\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m\u001B[38;5;250m \u001B[39mfield\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01mand\u001B[39;00m\u001B[38;5;250m \u001B[39mfield\u001B[38;5;241m.\u001B[39mislower()]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'scene' is not defined"
     ]
    }
   ],
   "source": [
    "print(f'Тип объекта: {type(scene)}')\n",
    "print(f'Поля объекта: {[field for field in dir(scene) if not field.startswith(\"_\") and field.islower()]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c69acc7",
   "metadata": {},
   "source": [
    "Каждая сцена содержит в себе данные о прошлом и будущем на 5 секунд (всего 10 секунд). Это время разбито на 50 дискретных таймстемпов с частотой  5Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bd706f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scene' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mГоризонт прошлого: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(scene\u001B[38;5;241m.\u001B[39mpast_vehicle_tracks)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, горизонт будущего: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(scene\u001B[38;5;241m.\u001B[39mfuture_vehicle_tracks)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'scene' is not defined"
     ]
    }
   ],
   "source": [
    "print(f'Горизонт прошлого: {len(scene.past_vehicle_tracks)}, горизонт будущего: {len(scene.future_vehicle_tracks)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab27433c",
   "metadata": {},
   "source": [
    "Индекс 0 в past_tracks соответсвтует -5 секундам в истории, индекс 24 -- нулевая секунда, момент предсказния."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c30f5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество машин в момент предсказания: 17\n",
      "Информация об одной из машин в момент предсказания:\n",
      "track_id: 34169\n",
      "position {\n",
      "  x: 3528.887235455813\n",
      "  y: -1845.6880594767722\n",
      "  z: 0.8689320729550655\n",
      "}\n",
      "dimensions {\n",
      "  x: 4.390752201556174\n",
      "  y: 2.0034280269183236\n",
      "  z: 1.7411829130317864\n",
      "}\n",
      "linear_velocity {\n",
      "  x: 0.08383738883850562\n",
      "  y: -0.03237506137534246\n",
      "}\n",
      "linear_acceleration {\n",
      "  x: 0.14328786721880105\n",
      "  y: -0.023524992679709048\n",
      "}\n",
      "yaw: -0.20406750287213143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Количество машин в момент предсказания: {len(scene.past_vehicle_tracks[-1].tracks)}')\n",
    "print('Информация об одной из машин в момент предсказания:')\n",
    "print(scene.past_vehicle_tracks[-1].tracks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626d0eef",
   "metadata": {},
   "source": [
    "В сцене есть поле `prediction_requests` содержащее id автомобилей, для которых необходимо сделать предсказание. Помимо этого реквесты помечены тегами, описывающими характер движения автомобиля. Полный список тегов можно найти в файле `tags.proto` [ссылка](https://github.com/yandex-research/shifts/blob/main/sdc/ysdc_dataset_api/proto/tags.proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa197c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track_id: 34169\n",
      "trajectory_tags: kStationary\n",
      "trajectory_tags: kUniform\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for r in scene.prediction_requests:\n",
    "    if r.track_id == scene.past_vehicle_tracks[-1].tracks[0].track_id:\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb70c73",
   "metadata": {},
   "source": [
    "Тэги есть так же и у сцен. Они описывают различные срезы данных, по которым проходило разбиение в соревновании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5516a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day_time: kAfternoon\n",
      "season: kAutumn\n",
      "track: Moscow\n",
      "sun_phase: kDaylight\n",
      "precipitation: kNoPrecipitation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(scene.scene_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f25da3e",
   "metadata": {},
   "source": [
    "Давайте нарисуем уже сцену и посмотрим, как оно выглядит не в скучных числах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8bfa84d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import yaml\n",
    "from matplotlib import collections as mc\n",
    "\n",
    "from ysdc_dataset_api.dataset import MotionPredictionDataset\n",
    "from ysdc_dataset_api.features import FeatureRenderer\n",
    "from ysdc_dataset_api.utils import transform_2d_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6091fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('renderer_config.yaml') as f:\n",
    "    renderer_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cde21bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/techtoker/tools/anaconda3/envs/yandex_sdc/lib/python3.8/site-packages/ysdc_dataset_api/features/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import ysdc_dataset_api.features\n",
    "\n",
    "print(ysdc_dataset_api.features.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6995c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer = FeatureRenderer(renderer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d2acea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../dataset/development_pb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0721d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MotionPredictionDataset(\n",
    "    dataset_path=dataset_path,\n",
    "    feature_producers=[renderer],\n",
    "    transform_ground_truth_to_agent_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bfa0e02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество сцен в датасете: 36605\n"
     ]
    }
   ],
   "source": [
    "print(f'Количество сцен в датасете: {dataset.num_scenes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "738eda18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_iter = iter(dataset)\n",
    "#\n",
    "# # Проитерируемся по датасету в поисках машины, проехавшей более 2 метров по одной из координат.\n",
    "# while True:\n",
    "#     data_item = next(dataset_iter)\n",
    "#     if data_item['ground_truth_trajectory'][-1, 0] > 2.0 or data_item['ground_truth_trajectory'][-1, 1] > 2.0:\n",
    "#\n",
    "#         if data_item['scene_tags']['track'] == 'Innopolis':\n",
    "#             # print(data_item)\n",
    "#\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "# real_idx = 0\n",
    "#\n",
    "# dataset_iter = iter(dataset)\n",
    "#\n",
    "# while True:\n",
    "#     data_item = next(dataset_iter)\n",
    "#     real_idx += 1\n",
    "#\n",
    "#     if data_item['scene_tags']['track'] == 'Innopolis':\n",
    "#         idx += 1\n",
    "#\n",
    "#         # if idx < 370:\n",
    "#         #     continue\n",
    "#         #\n",
    "#         # if idx > 400:\n",
    "#         #     break\n",
    "#\n",
    "#         # Plot vehicles occupancy, pedestrian occupancy, lane occupancy and road polygon\n",
    "#         plt.figure(figsize=(10, 10))\n",
    "#         plt.imshow(data_item['feature_maps'][0], origin='lower', cmap='binary', alpha=0.7)\n",
    "#         plt.imshow(data_item['feature_maps'][6], origin='lower', cmap='binary', alpha=0.5)\n",
    "#         plt.imshow(data_item['feature_maps'][13], origin='lower', cmap='binary', alpha=0.2)\n",
    "#         plt.imshow(data_item['feature_maps'][16], origin='lower', cmap='binary', alpha=0.1)\n",
    "#\n",
    "#         # Переведем ground truth траекторию агента в систему координат фичемапы\n",
    "#         transformed_gt = transform_2d_points(data_item['ground_truth_trajectory'], renderer.to_feature_map_tf)\n",
    "#         transformed_gt = np.round(transformed_gt - 0.5).astype(np.int32)\n",
    "#\n",
    "#         ax = plt.gca()\n",
    "#         ax.add_collection(mc.LineCollection([transformed_gt], color='green'))\n",
    "#         plt.savefig(f'./samples/res_{idx}.png')\n",
    "#\n",
    "#     print(real_idx)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3baa1fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "innopolis_scenes = []\n",
    "\n",
    "#dataset_iter = iter(dataset)\n",
    "\n",
    "for d_item in dataset:\n",
    "\n",
    "    if d_item['ground_truth_trajectory'][-1, 0] > 2.0 or d_item['ground_truth_trajectory'][-1, 1] > 2.0:\n",
    "\n",
    "        if d_item['scene_id'] == 'abbfe977229cd8f605de977495eee9f4':\n",
    "        #if d_item['scene_tags']['track'] == 'Innopolis':\n",
    "            innopolis_scenes.append(d_item)\n",
    "\n",
    "            print(len(innopolis_scenes))\n",
    "\n",
    "            if len(innopolis_scenes) == 2:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4d876286",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(innopolis_scenes)\n",
    "data_item = innopolis_scenes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a8ea99df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_item = dataset[0] #innopolis_scenes[44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d5bb08a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет для каждого объекта возвращает набор следующих полей: ['scene_id', 'track_id', 'scene_tags', 'ground_truth_trajectory', 'feature_maps']\n"
     ]
    }
   ],
   "source": [
    "print(f'Датасет для каждого объекта возвращает набор следующих полей: {[k for k in data_item.keys()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2087dedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры фичемап, которые нам отдал рендерер: (17, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(f'Размеры фичемап, которые нам отдал рендерер: {data_item[\"feature_maps\"].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "774ec110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot vehicles occupancy, pedestrian occupancy, lane occupancy and road polygon\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(data_item['feature_maps'][0], origin='lower', cmap='binary', alpha=0.7)\n",
    "plt.imshow(data_item['feature_maps'][6], origin='lower', cmap='binary', alpha=0.5)\n",
    "plt.imshow(data_item['feature_maps'][13], origin='lower', cmap='binary', alpha=0.2)\n",
    "plt.imshow(data_item['feature_maps'][16], origin='lower', cmap='binary', alpha=0.1)\n",
    "\n",
    "# Переведем ground truth траекторию агента в систему координат фичемапы\n",
    "transformed_gt = transform_2d_points(data_item['ground_truth_trajectory'], renderer.to_feature_map_tf)\n",
    "transformed_gt = np.round(transformed_gt - 0.5).astype(np.int32)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.add_collection(mc.LineCollection([transformed_gt], color='green'))\n",
    "plt.savefig('res.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[252, 249],\n       [254, 249],\n       [257, 249],\n       [259, 249],\n       [261, 249],\n       [263, 249],\n       [265, 249],\n       [267, 249],\n       [270, 249],\n       [272, 249],\n       [274, 249],\n       [276, 249],\n       [278, 249],\n       [280, 249],\n       [283, 249],\n       [286, 248],\n       [289, 248],\n       [292, 248],\n       [296, 248],\n       [299, 248],\n       [303, 247],\n       [307, 247],\n       [311, 247],\n       [316, 246],\n       [320, 246]], dtype=int32)"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_gt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "732fe5db",
   "metadata": {},
   "source": [
    "## Метрики\n",
    "\n",
    "Одними из общепринятых метрик для оценки качества предсказания траекторий являются Average Displacement Error и Final Displacement Error, а так же их модификации minADE@k, minFDE@k:\n",
    "- ADE - среднее по таймстемпам L2 отклонеие предсказания от ground truth\n",
    "- FDE - L2 отклонение последней предсказанной точки траектории от ground truth\n",
    "- minADE@k -- минимальное значение ADE по k наиболее вероятных предсказанных гипотез\n",
    "- minFDE@k -- минимальное значение FDE по k наиболее вероятных предсказанных гипотез"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425ca910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ade(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Insert your code for ADE computation below.\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.ndarray): shape (batch, n_timestamps, 2)\n",
    "        y_pred (np.ndarray): shape (batch, n_timestamps, 2)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: shape (batch, 1)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938e4353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fde(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Insert your code for FDE computation below.\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.ndarray): shape (batch, n_timestamps, 2)\n",
    "        y_pred (np.ndarray): shape (batch, n_timestamps, 2)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: shape (batch, 1)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b73715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_ade(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Insert your code for minADE computation below.\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.ndarray): shape (batch, n_timestamps, 2)\n",
    "        y_pred (np.ndarray): shape (batch, n_modes, n_timestamps, 2)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: shape (batch, 1)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4b780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_fde(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Insert your code for minFDE computation below.\n",
    "    \n",
    "    Args:\n",
    "        y_true (np.ndarray): shape (batch, n_timestamps, 2)\n",
    "        y_pred (np.ndarray): shape (batch, n_modes, n_timestamps, 2)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: shape (batch, 1)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40cc8cd",
   "metadata": {},
   "source": [
    "## Модель с константным предсказанием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3b90685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "\n",
    "from ysdc_dataset_api.features import FeatureVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "12b30f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel(torch.nn.Module):\n",
    "    def __init__(self, gt_time_grid):\n",
    "        super().__init__()\n",
    "        self._gt_time_grid = torch.tensor(gt_time_grid)\n",
    "    \n",
    "    def forward(self, velocity):\n",
    "        states = torch.einsum('bc,t->btc', velocity, self._gt_time_grid)\n",
    "        return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "136c755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaselineModel(np.linspace(0.2, 5, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5d851c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vectorizer_config.yaml') as f:\n",
    "    vectorizer_config = yaml.safe_load(f)\n",
    "vectorizer = FeatureVectorizer(vectorizer_config)\n",
    "\n",
    "dataset = MotionPredictionDataset(\n",
    "    dataset_path='./test/',\n",
    "    prerendered_dataset_path='./test/',\n",
    "    feature_producers=[vectorizer],\n",
    "    transform_ground_truth_to_agent_frame=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "11f2fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1cf563ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x0000021FFEC19160>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\impor\\.anaconda3\\envs\\yandex_sdc\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1466, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"C:\\Users\\impor\\.anaconda3\\envs\\yandex_sdc\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1430, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"C:\\Users\\impor\\.anaconda3\\envs\\yandex_sdc\\lib\\multiprocessing\\process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"C:\\Users\\impor\\.anaconda3\\envs\\yandex_sdc\\lib\\multiprocessing\\popen_spawn_win32.py\", line 108, in wait\n",
      "    res = _winapi.WaitForSingleObject(int(self._handle), msecs)\n",
      "KeyboardInterrupt: \n",
      "0it [00:21, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ade' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[150], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m tqdm\u001B[38;5;241m.\u001B[39mtqdm(dataloader):\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;66;03m# Возьмём скорость по (x, y) в последний известный момент времени\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m model(batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvector_features\u001B[39m\u001B[38;5;124m'\u001B[39m][:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m:\u001B[38;5;241m4\u001B[39m])\n\u001B[1;32m----> 6\u001B[0m     ades\u001B[38;5;241m.\u001B[39mappend(\u001B[43made\u001B[49m(batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mground_truth_trajectory\u001B[39m\u001B[38;5;124m'\u001B[39m], predictions))\n\u001B[0;32m      7\u001B[0m     fdes\u001B[38;5;241m.\u001B[39mappend(fde(batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mground_truth_trajectory\u001B[39m\u001B[38;5;124m'\u001B[39m], predictions))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'ade' is not defined"
     ]
    }
   ],
   "source": [
    "ades = []\n",
    "fdes = []\n",
    "for batch in tqdm.tqdm(dataloader):\n",
    "    # Возьмём скорость по (x, y) в последний известный момент времени\n",
    "    predictions = model(batch['vector_features'][:, -1, 2:4])\n",
    "    ades.append(ade(batch['ground_truth_trajectory'], predictions))\n",
    "    fdes.append(fde(batch['ground_truth_trajectory'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a2a013",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.concatenate(ades)), np.mean(np.concatenate(fdes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7546a6",
   "metadata": {},
   "source": [
    "## Визуализация предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abeffe69",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m i \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     10\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m10\u001B[39m))\n\u001B[0;32m---> 11\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(\u001B[43mbatch\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprerendered_feature_map\u001B[39m\u001B[38;5;124m'\u001B[39m][i][\u001B[38;5;241m0\u001B[39m], origin\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlower\u001B[39m\u001B[38;5;124m'\u001B[39m, cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.7\u001B[39m)\n\u001B[1;32m     12\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprerendered_feature_map\u001B[39m\u001B[38;5;124m'\u001B[39m][i][\u001B[38;5;241m6\u001B[39m], origin\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlower\u001B[39m\u001B[38;5;124m'\u001B[39m, cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m)\n\u001B[1;32m     13\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprerendered_feature_map\u001B[39m\u001B[38;5;124m'\u001B[39m][i][\u001B[38;5;241m13\u001B[39m], origin\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlower\u001B[39m\u001B[38;5;124m'\u001B[39m, cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'batch' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Тк в датасете выше мы использовали готовые пре-рендеренные картинки (см prerendered_dataset_path),\n",
    "# сделаем себе соответсвующий рендерер, чтобы извлечь из него трансформ для визуализации.\n",
    "with open('prerendered_images_config.yaml') as f:\n",
    "    renderer_config = yaml.safe_load(f)\n",
    "renderer = FeatureRenderer(renderer_config)\n",
    "\n",
    "\n",
    "# Plot vehicles occupancy, pedestrian occupancy, lane occupancy and road polygon\n",
    "i = 1\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(batch['prerendered_feature_map'][i][0], origin='lower', cmap='binary', alpha=0.7)\n",
    "plt.imshow(batch['prerendered_feature_map'][i][6], origin='lower', cmap='binary', alpha=0.5)\n",
    "plt.imshow(batch['prerendered_feature_map'][i][13], origin='lower', cmap='binary', alpha=0.2)\n",
    "plt.imshow(batch['prerendered_feature_map'][i][16], origin='lower', cmap='binary', alpha=0.1)\n",
    "\n",
    "# Переведем ground truth траекторию агента в систему координат фичемапы\n",
    "transformed_gt = transform_2d_points(batch['ground_truth_trajectory'][i].numpy(), renderer.to_feature_map_tf)\n",
    "transformed_gt = np.round(transformed_gt - 0.5).astype(np.int32)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.add_collection(mc.LineCollection([transformed_gt], color='green'))\n",
    "\n",
    "prediction = predictions[i].numpy().astype(np.float32)\n",
    "transformed_prediction = transform_2d_points(prediction, renderer.to_feature_map_tf)\n",
    "ax.add_collection(mc.LineCollection([transformed_prediction], color='red'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09784a4b",
   "metadata": {},
   "source": [
    "## Мультимодальность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e3c573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d17eb708",
   "metadata": {},
   "source": [
    "## Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff230e9e",
   "metadata": {},
   "source": [
    "В качестве задания предлагается обучить нейросетку для предсказания траекторий и побить наш бейзлайн.\n",
    "Ссылки на данные:\n",
    "- [трейн](https://disk.yandex.ru/d/tuTwRSLL-KFqjg)\n",
    "- [валидация](https://disk.yandex.ru/d/3Lu6_6BgwkXlgw)\n",
    "- [тест](https://disk.yandex.ru/d/M_4ED0r19OnSrg)\n",
    "\n",
    "В своей реализации вы можете использовать векторные фичи для объекта, а так же растровые картинки.\n",
    "\n",
    "\n",
    "Критерии оценки (subject to change):\n",
    "- сделать нейросетку, которая бьёт бейзлайн (4 балла)\n",
    "- использовать картиночные фичи (4 балла)\n",
    "- научить сеть предсказывать более одной моды (2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для использования картиночных фичей можно использовать уже нарендеренные картинки (они есть в датасете).\n",
    "# Рендерить с нуля может быть довольно долго.\n",
    "# Пример использования готовых картинок в датасете:\n",
    "\n",
    "# dataset = MotionPredictionDataset(\n",
    "#     dataset_path='/Users/gerrok/test/',\n",
    "#     prerendered_dataset_path='/Users/gerrok/test/',  # Тут мы указываем путь, где искать готовые картинки\n",
    "#     feature_producers=[vectorizer],\n",
    "#     transform_ground_truth_to_agent_frame=True,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
